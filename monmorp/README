* About MONMORP
　　MongoDB上で動作する形態素解析エンジンです。
　　MongoDBのコレクションから直接、手軽に形態素解析を掛けられます。
　　結果は別のコレクションに保存するかJSON形式で標準出力に出力します。

　　形態素解析に利用する辞書はIPADICをパースし、すこし手を加えて利用します。


* 特徴
　　単純な辞書にマッチさせるだけでなく、ある程度文法や活用形を判断しているので
　　正確な分割や、品詞の抽出ができます。

　　　とはいえ、短い単語は混ざるケースもあります。

　　MongoDB上に辞書を持ち、外来語や数値などを検出して、解析中にも辞書をアップデートしながら解析します。

* ディレクトリ構成

　　[analysis]
　　　|- mongo.env            : MongoDBのパスを設定
　　　|- [monmorp]
　　      |- README
　　      |- [bin]
　　      |   |- gendic.sh    : IPADICからMONMPRP用の辞書をビルドします
　　      |   |- parse.sh     : 形態素解析を行います
　　      |- [lib]            : 
　　      |   |- *            : スクリプト群
　　      |- [data]           : 一時データ用
　　      |   |- testdata.json: テストデータ
　　      |- [html]           : testdata.sh用

* クイックスタート
　　０．mongo.envを編集するか環境変数を設定

　　　　　それぞれのコマンドのパスを設定する

　　１．IPA辞書をダウンロード

　　　　　pushd ./data
　　　　　wget http://iij.dl.sourceforge.jp/ipadic/24435/ipadic-2.7.0.tar.gz
　　　　　tar xzf ipadic-2.7.0.tar.gz
　　　　　popd

　　２．辞書をビルド（辞書コレクション＝"analysis.dictionary"

　　　　　./bin/gendic.sh -D analysis.dictionary -i data/ipadic-2.7.0

　　３．動作確認（形態素解析結果が出力されます

　　　　　./bin/parse.sh -D analysis.dictionary -i "こんにちは世界。" -o - -V

　　４．テストデータをMongoDBに投入

　　　　　mongoimport --drop -d test -c testdoc --file data/testdata.json

　　５．複数ドキュメントを一気に解析

　　　　　./bin/parse.sh -D analysis.dictionary -c test.testdoc -f body -o test.out -C
　　　　　./bin/parse.sh -D analysis.dictionary -c test.testdoc -f body -o test.out


　　　　並列処理する場合：

　　　　　./bin/parse.sh -D analysis.dictionary -c test.testdoc -f body -o test.out -C
　　　　　./bin/parse.sh -D analysis.dictionary -c test.testdoc -f body -o test.out -j 4


　　６．結果を確認

　　　　　mongo test <<<'db.out.find().sort({docid:1,idx:1})'

* 辞書詳細：( defalut: analysis.dictionary )

　　　　辞書はIPADICを元に同字意義語や活用形などを考慮した状態に直して使います。

　　辞書コレクションの構造

　　　　w: 単語 or 活用候補配列
　　　　　　　　単語か活用候補


　　　　h: 先頭文字配列
　　　　　　　　最長マッチにかける為のインデックス用の要素

　　　　l: 文字列長　　　　
　　　　　　　　最長マッチにかける為のインデックス用の要素

　　　　s: 品詞優先度
　　　　　　　　最長マッチにかける為のインデックス用の要素

　　　　c: コスト
　　　　　　　　未使用（品詞で別けた方が結果が良かったので使わなくなった）

　　　　f: 活用系区分
　　　　　　　　1: 打ち切り可能
　　　　　　　　2: 後ろ助詞、助動詞必須
　　　　　　　　3: 後ろ動詞可能（通常は動詞＋動詞は無い）
　　　　　　　　4: 後ろ名詞優先

　　　　　※ この辺は今後チューニングが必要

　　インデックス：

　　　　{h:1,l:-1,s:1}
　　　　{w:1}
　　　　{t:1}

* 結果コレクション

　　　形態素解析の結果であると共に、Vectorize結果になっています。

　　　　docidとcを集計するとDF,TFが得られます。

　　結果コレクションの構造

　　　　docid: 元ドキュメントの_id

　　　　idx: 単語の現れた順

　　　　pos: ドキュメント中の単語の位置

　　　　w: 単語

　　　　l: 単語長
　　　　　　活用している場合は同じ単語でも長さが変わります

　　　　c: 単語ID（辞書コレクション中の_id）


　　インデックス：

　　　　{docid:1,idx:1}


* 並列実行の動作と性能：

　　ジョブ管理コレクション：　<結果コレクション>.job 

　　　　MONMORPは各ジョブが同じドキュメントを処理する事を防ぐためにジョブ管理コレクションを作る。
　　　　同じ結果コレクション名に対する処理は、同一ホストは勿論、別ホストで起動したジョブでも正常に動作できる。

　　プライマリノードへの処理

　　　　MONMORPの形態素解析中の書き込み処理は以下の３つである。
　　　　　１．ジョブ管理コレクションへのドキュメントID登録
　　　　　２．解析結果の書き込み
　　　　　３．カタカナ、アルファベット、数値を新単語として辞書へ登録

　　性能面

　　　　プライマリノードのホスト
　　　　　MONGO_NODE環境変数をローカルホスト（プライマリノード）に指定した場合
　　　　　全てのDB操作がローカルホストで処理出来る為、一番高速に動作できる。

　　　　　他のホストでもジョブを走らせる時は、mongod用のコアを１つ分は確保して置くと良い。

　　　　セカンダリのホスト
　　　　　MONGO_NODE環境変数をローカルホスト（セカンダリノード）に指定した場合
　　　　　ドキュメントの取得と、辞書の参照（最大ボトルネック）をローカルホストから行える為、そこそこ早い。

　　　　他のホスト　　　　
　　　　　全てのDB操作をリモートから行う為、低速になる。
　　　　　しかしMongoDBノード以外のCPUリソースを利用できるメリットがある。


* 既知の問題
　MONMORPは通常、実用上問題ない程度の精度で解析できますが
　幾つか間違った分割をしてしまうケースが判明しています。

　１．動詞＋名詞のパターンで判定を間違える場合があります。

　　　- これを買うとしあわせに、、
　　　- これを買うときは、、



　　　- これ|を|買う|と|しあわせ|に|、、
　　　- これ|を|買う|とき|は|、、

　　　正しくはこの様に分割すべきですが、MONMORPでは以下の様に分割してしまいます。

　　　- これ|を|買う|と|しあわせ|に|、、
　　　- これ|を|買う|と|き|は|、、

　　　これは動詞の活用形で、後ろに助詞、助動詞、動詞などが続く可能性がある場合、助詞を優先するようになっているからです。
　　　名詞を優先したり、最長マッチを採用してしまうと

　　　- これ|を|買う|とし|あわせ|に|、、

　　　この様な結果を得てしまい、難しく解決できていません。
　　　これを解くには、もう少し深い探索を実装する必要があるのですが、性能との兼ね合いもあるので保留しています。


　２．外来語がサ変接続する場合

　　　- ビルドする、、

　　　- ビルド|する|、、
　　　正しくはこの様に分割すべきですが、MONMORPでは以下の様に分割してしまいます。

　　　- ビルド|す|る|、、

　　　MONMORPは連続したアルファベット、数字、カタカナを一般名詞として扱います。
　　　名詞の直後には基本的に動詞は来ないのですが（『アメリカ』する。など）、例外的に『する』に接続する場合があります。
　　　特に『する』はサ行変格活用で厄介な活用をする動詞で、助詞などと誤判定し易く、現状助ける手立てがありません。

　　　どうしてもこのパターンを広いたい場合は辞書に以下のドキュメントを登録する必要があります。
　　　　db.dictionary.update({w:"ビルド"},{w:"ビルド", l:3 , c:0, s:0 , t:["名詞","サ変接続"],p:["ビルド"]})

